{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "daoq0LbOQO_u"
   },
   "outputs": [],
   "source": [
    "#Data base description \n",
    "#https://www.kaggle.com/mlg-ulb/creditcardfraud/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "gMydS4MSJOCE",
    "outputId": "8c02450e-8bd8-45f5-e07c-07463c2e7db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-518fd6ac85da>:85: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 0 Current loss:1.3893 Ellasped Time: 1.86 seconds\n",
      "Current Accuracy: 0.17%\n",
      "Epoch: 10 Current loss:1.3884 Ellasped Time: 1.27 seconds\n",
      "Current Accuracy: 38.39%\n",
      "Epoch: 20 Current loss:1.3627 Ellasped Time: 1.30 seconds\n",
      "Current Accuracy: 13.14%\n",
      "Epoch: 30 Current loss:1.2525 Ellasped Time: 1.29 seconds\n",
      "Current Accuracy: 82.93%\n",
      "Epoch: 40 Current loss:1.0866 Ellasped Time: 1.30 seconds\n",
      "Current Accuracy: 97.43%\n",
      "Epoch: 50 Current loss:0.9643 Ellasped Time: 1.31 seconds\n",
      "Current Accuracy: 98.43%\n",
      "Epoch: 60 Current loss:0.8964 Ellasped Time: 1.33 seconds\n",
      "Current Accuracy: 99.32%\n",
      "Epoch: 70 Current loss:0.8677 Ellasped Time: 1.30 seconds\n",
      "Current Accuracy: 99.76%\n",
      "Epoch: 80 Current loss:0.8482 Ellasped Time: 1.28 seconds\n",
      "Current Accuracy: 99.67%\n",
      "Epoch: 90 Current loss:0.8423 Ellasped Time: 1.29 seconds\n",
      "Current Accuracy: 99.70%\n",
      "Final Accuracy: 99.56%\n",
      "Final fraud specific  Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 17 19:20:56 2018\n",
    "\n",
    "@author: Sanjeev Jha\n",
    "\"\"\"\n",
    "#Importing the library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "##################---------------EDA-----------######################\n",
    "#IMPORT AND STORE THE DATA SET\n",
    "\n",
    "credit_card_data=pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "##########-------------------SPLITTING DATA INTO 2 TUPPLE OF TRAING ANG AND TEST SET(DATA PREPROCESSING) -------------------######\n",
    "\n",
    "#1. Shuffle and randomizethe data to remove the baise \n",
    "shuffled_data=credit_card_data.sample(frac=1)\n",
    "\n",
    "\n",
    "#2. One-hot encoding for change Class columns into class_0([1,0] for legit data) and class_1([0,1] for fraudlent data)\n",
    "one_hot_data=pd.get_dummies(shuffled_data, columns=[\"Class\"])\n",
    "\n",
    "#3 . Normalize the data by changeing all the value in between zero and one \n",
    "normalized_data=(one_hot_data - one_hot_data.min())/(one_hot_data.max() - one_hot_data.min())\n",
    "\n",
    "#4. Splitting up the data into data frmae X(Input)/y(target) columns V1 through V28 in df_X and columns Class_0 and Class_1 in df_y\n",
    "df_X=normalized_data.drop([\"Class_0\", \"Class_1\"], axis=1)\n",
    "df_y=normalized_data[[\"Class_0\", \"Class_1\"]]\n",
    "\n",
    "#5. Convert data frame into numpy array format (float 32)\n",
    "arr_X, arr_y= np.asarray(df_X.values, dtype=\"float32\"), np.asarray(df_y.values, dtype=\"float32\")\n",
    "\n",
    "#5. Allocate first 80% shuffle data in training tupple and next 20 % data into test tupple\n",
    "train_size=int(0.8 * len(arr_X))\n",
    "(raw_X_train, raw_y_train) = (arr_X[:train_size], arr_y[:train_size])\n",
    "(raw_X_test, raw_y_test)=(arr_X[train_size:], arr_y[train_size:]) \n",
    "\n",
    "# 6. We have to much baise in our target data so we need to remove the basie by multiplaying with weight \n",
    "count_legit, count_fraud= np.unique(credit_card_data['Class'], return_counts=True)[1]\n",
    "\n",
    "fraud_ratio=float(count_fraud/(count_legit + count_fraud)) \n",
    "weighting = 1/fraud_ratio\n",
    "raw_y_train[:, 1]= raw_y_train[:, 1] * weighting \n",
    "\n",
    "# 7. We have 30 cells for input and 2 cells for output \n",
    "input_dimesions=arr_X.shape[1]\n",
    "ouput_dimensions=arr_y.shape[1]\n",
    "\n",
    "#8. Number of cells in 2 hidden layers\n",
    "num_layers_1_cells=100\n",
    "num_layers_2_cells=150\n",
    "\n",
    "#We will use these placeholder as input to use at when it come time to train it at run time\n",
    "X_train_node=tf.placeholder(tf.float32, [None, input_dimesions], name=\"X_train\")\n",
    "y_train_node=tf.placeholder(tf.float32, [None, ouput_dimensions], name=\"y_train\")\n",
    "\n",
    "# we will use these input at test tim e\n",
    "X_test_node=tf.constant(raw_X_test, name=\"X_test\")\n",
    "y_test_node=tf.constant(raw_y_test, name=\"y_test\")\n",
    "\n",
    "#First layers of weight and baises\n",
    "weight_1_node=tf.Variable(tf.zeros([input_dimesions,num_layers_1_cells]), name=\"weight_1\") \n",
    "biases_1_node=tf.Variable(tf.zeros([num_layers_1_cells]), name=\"biases_1\") \n",
    "\n",
    "#Second layers of weight and baises\n",
    "weight_2_node=tf.Variable(tf.zeros([num_layers_1_cells, num_layers_2_cells]), name=\"weight_2\") \n",
    "biases_2_node=tf.Variable(tf.zeros([num_layers_2_cells]), name=\"biases_2\") \n",
    "\n",
    "#Output layers of weight and baises\n",
    "weight_3_node=tf.Variable(tf.zeros([num_layers_2_cells, ouput_dimensions]), name=\"weight_3\") \n",
    "biases_3_node=tf.Variable(tf.zeros([ouput_dimensions]), name=\"biases_3\") \n",
    "\n",
    "#Function to run the input from three layers(2 hidden layers, one output layers)\n",
    "\n",
    "def network(input_tensor):\n",
    "    #if you will draw the graph between target and input then you can see Sigmoid will fit \n",
    "    layer1=tf.nn.sigmoid(tf.add(tf.matmul(input_tensor, weight_1_node), biases_1_node))\n",
    "    #Droput will prevenyt model to become lazzy and over confident\n",
    "    layer2=tf.nn.dropout(tf.nn.sigmoid(tf.add(tf.matmul(layer1, weight_2_node),biases_2_node)), 0.85) \n",
    "    #Softmax work very well with with one hot encoding and multiple output\n",
    "    layer3=tf.nn.softmax(tf.add(tf.matmul(layer2, weight_3_node), biases_3_node))\n",
    "    return layer3\n",
    "\n",
    "# Used to predict what result has been given traing and testing data, just fir reminder x_TRAIN_nODE IS PLACE HOLDER NAD WE WILL ENTER THE RESULTS AT TRAING TIMER\n",
    "y_train_predection = network(X_train_node)\n",
    "y_test_predection = network(X_test_node)\n",
    "\n",
    "#Cross entropy loss function mesure difference between actula output and predicted output \n",
    "cross_entropy=tf.losses.softmax_cross_entropy(y_train_node, y_train_predection)\n",
    "\n",
    "#Adamn Optimizer(Momentum and RMSpROP) funcion will try to minimize the cross entropy loss function BUT IT WILL CHNGE THE LERNING RATE VALUE OF ALL THREE LAYERS BY 0.005\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(0.005).minimize(cross_entropy)\n",
    "\n",
    "#Functions to cal culate accuracy of actual results and predicted results \n",
    "\n",
    "def calculate_accuracy(actual, predicted):\n",
    "    actual = np.argmax(actual, 1)\n",
    "    predicted = np.argmax(predicted, 1) \n",
    "    return (100*np.sum(np.equal(predicted, actual))/predicted.shape[0])\n",
    "    \n",
    "\n",
    "#Train the model \n",
    "num_epochs=100\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time=time.time()\n",
    "        _, cross_entroppy_score= session.run([optimizer, cross_entropy], \n",
    "                                             feed_dict={X_train_node: raw_X_train, y_train_node: raw_y_train})\n",
    "        if epoch % 10 == 0:\n",
    "            timer=time.time() - start_time\n",
    "            print('Epoch: {}'.format(epoch), 'Current loss:{0:.4f}'.format(cross_entroppy_score), 'Ellasped Time: {0:.2f} seconds'.format(timer))\n",
    "            final_y_test = y_test_node.eval()\n",
    "            final_y_test_predection = y_test_predection.eval()\n",
    "            final_accurecy = calculate_accuracy(final_y_test, final_y_test_predection)\n",
    "            #print the accuracy on over all data sets \n",
    "            print('Current Accuracy: {0:.2f}%'.format(final_accurecy))\n",
    "    final_y_test = y_test_node.eval()\n",
    "    final_y_test_predection = y_test_predection.eval()\n",
    "    final_accurecy = calculate_accuracy(final_y_test, final_y_test_predection)\n",
    "    #print the accuracy on over all data sets \n",
    "    print('Final Accuracy: {0:.2f}%'.format(final_accurecy))\n",
    "            \n",
    "#Prediction specific to fraud \n",
    "\n",
    "final_fraud_y_test= final_y_test[final_y_test[:, 1] == 1]\n",
    "final_fraud_y_test_prediction= final_y_test_predection[final_y_test[:, 1] == 1]\n",
    "final_fraud_accuracy=calculate_accuracy(final_fraud_y_test, final_fraud_y_test)           \n",
    "print('Final fraud specific  Accuracy: {0:.2f}%'.format(final_fraud_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Credit_Card _Fraud_Detection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
